<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LSP Benchmark Results | Python Type Coverage</title>
    <link rel="stylesheet" href="styles/lsp-benchmark.css">
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.1/dist/chart.umd.min.js"></script>
</head>
<body>
    <header class="hero">
        <div class="container">
            <h1>üöÄ LSP Performance Benchmarks</h1>
            <p class="subtitle">Daily performance analysis of Python type checkers</p>
            <p class="description">
                Measuring <code>textDocument/definition</code> (Go to Definition) latency and accuracy 
                across popular Python packages
            </p>
            <div class="date-selector">
                <label for="dateSelect">View results for:</label>
                <input type="date" id="dateSelect" class="date-input">
                <button id="loadDateBtn" class="date-btn">Load</button>
                <button id="latestBtn" class="date-btn">Latest</button>
            </div>
            <div class="last-updated" id="lastUpdated">Loading...</div>
        </div>
    </header>

    <nav class="nav-bar">
        <div class="container">
            <a href="/index.html" class="back-link">‚Üê Back to Type Coverage</a>
            <div class="nav-links">
                <a href="#comparison">Comparison</a>
                <a href="#packages">By Package</a>
                <a href="#methodology">Methodology</a>
            </div>
        </div>
    </nav>

    <main class="container">
        <!-- Comparison Charts -->
        <section id="comparison" class="section">
            <h2>üìà Type Checker Comparison</h2>
            
            <div class="chart-grid">
                <div class="chart-card">
                    <h3>Average Latency (ms)</h3>
                    <p class="chart-description">Lower is better - time to resolve "Go to Definition"</p>
                    <canvas id="latencyChart"></canvas>
                </div>
                <div class="chart-card">
                    <h3>OK Rate (%)</h3>
                    <p class="chart-description">Higher is better - requests that completed without timeout/error</p>
                    <canvas id="okChart"></canvas>
                </div>
                <div class="chart-card">
                    <h3>Success Rate (%)</h3>
                    <p class="chart-description">Higher is better - valid definitions found</p>
                    <canvas id="successChart"></canvas>
                </div>
            </div>

            <div class="chart-card full-width">
                <h3>Latency by Package</h3>
                <p class="chart-description">Average "Go to Definition" latency per package (lower is better)</p>
                <canvas id="packageComparisonChart"></canvas>
            </div>
        </section>

        <!-- Detailed Results Table -->
        <section id="packages" class="section">
            <h2>üìã Detailed Results</h2>
            
            <div class="filter-bar">
                <input type="text" id="packageSearch" placeholder="Search packages..." class="search-input">
                <select id="sortBy" class="filter-select">
                    <option value="ranking">Sort by Ranking</option>
                    <option value="name">Sort by Name</option>
                    <option value="latency">Sort by Latency</option>
                    <option value="success">Sort by Success Rate</option>
                </select>
            </div>

            <div class="table-container">
                <table class="results-table" id="resultsTable">
                    <thead>
                        <tr>
                            <th>Package</th>
                            <th>Type Checker</th>
                            <th>Avg Latency</th>
                            <th>P50 Latency</th>
                            <th>P95 Latency</th>
                            <th>OK %</th>
                            <th>Success %</th>
                        </tr>
                    </thead>
                    <tbody id="resultsBody">
                        <tr>
                            <td colspan="7" class="loading-row">Loading results...</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </section>

        <!-- Methodology Section -->
        <section id="methodology" class="section">
            <h2>üìê Methodology</h2>
            <div class="methodology-content">
                <div class="method-card">
                    <h3>üéØ What We Measure</h3>
                    <p>
                        We benchmark the <code>textDocument/definition</code> LSP request (Go to Definition) 
                        across different type checker language servers. This is one of the most commonly used 
                        IDE features for code navigation.
                    </p>
                </div>
                <div class="method-card">
                    <h3>üîÑ Test Process</h3>
                    <ol>
                        <li>Clone the top Python packages from GitHub</li>
                        <li>Start all type checker LSP servers in parallel</li>
                        <li>Pick random Python files and identifier positions</li>
                        <li>Send identical "Go to Definition" requests to all servers simultaneously</li>
                        <li>Measure latency and verify if returned locations are valid</li>
                    </ol>
                    <p class="method-note">
                        <strong>‚è±Ô∏è Timeout:</strong> Requests have a 10-second timeout. 
                        Timeouts are counted as failures and excluded from latency statistics.
                    </p>
                    <p class="method-note">
                        <strong>üîÑ Parallel Execution:</strong> All type checkers receive identical test cases 
                        and run simultaneously. No warmup runs are performed.
                    </p>
                </div>
                <div class="method-card">
                    <h3>üìä Metrics Explained</h3>
                    <ul>
                        <li><strong>Latency:</strong> Time (ms) from request to response (excludes timeouts)</li>
                        <li><strong>P50/P95:</strong> 50th/95th percentile latencies</li>
                        <li><strong>OK Rate:</strong> Percentage of requests that completed without timeout or error (indicates reliability)</li>
                        <li><strong>Success Rate:</strong> Percentage of requests that returned a valid definition location pointing to a real file (indicates accuracy)</li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- Legend -->
        <section class="section">
            <h2>üè∑Ô∏è Type Checkers & Language Servers</h2>
            <div class="legend-grid">
                <div class="legend-item pyright">
                    <span class="legend-color"></span>
                    <div class="legend-info">
                        <strong>Pyright</strong>
                        <span class="legend-version" id="version-pyright"></span>
                        <span>Type checker and language server for Python by Microsoft</span>
                    </div>
                </div>
                <div class="legend-item pyrefly">
                    <span class="legend-color"></span>
                    <div class="legend-info">
                        <strong>Pyrefly</strong>
                        <span class="legend-version" id="version-pyrefly"></span>
                        <span>Type checker and language server for Python by Meta</span>
                    </div>
                </div>
                <div class="legend-item ty">
                    <span class="legend-color"></span>
                    <div class="legend-info">
                        <strong>ty</strong>
                        <span class="legend-version" id="version-ty"></span>
                        <span>Type checker and language server for Python by Astral</span>
                    </div>
                </div>
                <div class="legend-item zuban">
                    <span class="legend-color"></span>
                    <div class="legend-info">
                        <strong>Zuban</strong>
                        <span class="legend-version" id="version-zuban"></span>
                        <span>Type checker and language server for Python by the creator of Jedi LSP</span>
                    </div>
                </div>
            </div>
        </section>
    </main>

    <footer class="footer">
        <div class="container">
            <p>Part of the <a href="https://github.com/lolpack/type_coverage_py">Python Type Coverage</a> project</p>
            <p>Benchmarks run daily via GitHub Actions</p>
        </div>
    </footer>

    <script src="scripts/lsp-benchmark.js"></script>
</body>
</html>
